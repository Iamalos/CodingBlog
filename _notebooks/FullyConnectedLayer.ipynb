{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "> \"Creating a fully-connected layer\"\n",
    "\n",
    "- toc:true- branch: master- badges: true- comments: true\n",
    "- author: Ivan Dolgushev\n",
    "- categories: [fastpages, deeplearning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "from exp.nb_MatrixExample import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "   \n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        (x_train, y_train),(x_valid, y_valid), _ = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train, x_valid,y_valid))\n",
    "\n",
    "def normalize(x,m,s): return (x-m) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab for this example [MNIST](http://yann.lecun.com/exdb/mnist/) data. MNIST data is a popular dataset for machine learning and deep learning and conists of handwritted digits from 0 to 9. By modern standards the dataset is considered to be trivial with many algorithms reaching >99% test accuracy.\n",
    "\n",
    " MNIST has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    " \n",
    " There are many different ways to grab MNIST dataset. We leverage FastAI `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set has 50 000 observations, each observation has 784 data points. This represents flattened 28 x 28 pixels of the resulting image. We can convert 784 vector back to a matrix form and plot it for vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.imshow(x_train[0].view(28,28));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a usual first step we normalize our data - subtract the mean and divide by the standard deviation of the __train dataset__. it is important to use the same mean and standard deviation while normalizing training and validation / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid,train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near_zero(a, tol=1e-3): assert a.abs() < tol, f\"Near zero: {a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(1 - x_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n,m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of weights is __crucial__ to the training of the neural net. Using poor initialization could lead to very slow convergence of the loss function or even exploding. If weights are below 1, they will get smaller and smaller until they almost vanish and does not contribute to network learning.\n",
    "\n",
    "We can look at a simplified example, inspired by [post](https://prateekvjoshi.com/2016/03/29/understanding-xavier-initialization-in-deep-neural-networks/), to understand why weights are important. If our input for activation __z__ is near zero, sigmoid activation function degenerates to a linear one, which means it does not bring any new information. On the other hand, if **z** becomes too big or too small, activation function is flat at these areas and its gradient is approaching zero. We want the variance and bias for each layer to remain stable.\n",
    "\n",
    "We  often don't worry about this as deep learning frameworks implement the necessary weights initialization under the hood, but it is still important to understand why it matters this much. I discuss weight initialization in greater details in separate posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "seaborn.set(style='ticks')\n",
    "z = torch.linspace(-6,6,100)\n",
    "sigmoid = [1 / (1 + math.exp(-x)) for x in z]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(z, sigmoid, c='r', label = r\"$ \\frac{1}{1+e^{- z}}$\")\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "seaborn.despine(ax=ax, offset=0)\n",
    "ax.spines['left'].set_position('zero')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='22');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is for each layer to have mean of 0.0 and variance  of 1.0 for every layer in order to avoid gradient vanishing or exploding. This issues was tackled by Xavier in his paper [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html).\n",
    "\n",
    "Let's briefly discuss the reasoning behind his approach. <br>\n",
    "Consider a fully-connected linear layer: $$ y = x * w + b$$ which is $$ y = x_{1}*w_{1} + x_{2}*w_{2} + ... + x_{N}*w_{N} + b $$. \n",
    "\n",
    "Our goal is to make the variance of $y$ equal to $1$. Assuming independence between $x$ and $y$ we have the following formula: \n",
    "\n",
    "$$Var(x*y) = Var(x)*Var(y) + (Var(x)*E(y))^2 + (Var(y)*E(x))^2$$\n",
    "\n",
    "In our case $w_{i}$ was drawn from normal distrubution with zero mean and $x$ were normalized , thus for each i-th term we have:\n",
    "\n",
    "$$ Var(x_{i}*w_{i}) = Var(x_{i}) * Var(w_{i}) + (Var(x_{i})*0)^2 + (1 * 0) ^2  = Var(x_{i}) * Var(w_{i})) $$\n",
    "\n",
    "We have N identically distributed elements, thus:\n",
    "$$ Var(y) = \\sum_{i=1}^{N} Var(x_{i}) * Var(w_{i}) = N * Var(x_{i}) * Var(w_{i}))  $$\n",
    "\n",
    "We want our input to the activation function ($y$) to have the same variance as the previous layer ($x$) in order to have stability in the system. This implies, that \n",
    "\n",
    "$$ N * Var(w_{i}) = 1 $$ \n",
    "$$or$$ \n",
    "$$ Var(w_{i}) = 1 / N $$\n",
    "\n",
    "This is what is called _Xavier_ initialization. Let's proceed with it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier initialization\n",
    "w1 = torch.randn(m, nh) / math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1) / math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that mean and variance are equal to 0 and 1\n",
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std() - 1/math.sqrt(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x,w,b): return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lin(x_train, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0198), tensor(1.0244))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, after applying linear layer, we succeeded in our goal - mean and variance of the input to activation function is 0 and 1 (almost). But this is not the end of the story - we have to actuall pass the results through the activation function. And the results itself will be the input to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4137), tensor(0.5895))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(lin(x_train, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying relu our mean and variance are distorted - relu clamps all negative values to zero, thus reducting variance by half and shifting mean by 0.5. We have to take into account when initializing the weigths. This is addressed by using _kaiming initialization_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming init for relu\n",
    "w1 = torch.randn(m, nh) * math.sqrt(2/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5944), tensor(0.8434))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(lin(x_train, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still not perfect, but is much better than the inital approach. We could also subtract 0.5 to shift mean back to 0 (relu clamped the negative values and thus distorted the mean upwards). This initialization is implemented for us in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.zeros(m, nh)\n",
    "init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu(lin(x_train,w1,b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4932), tensor(0.7707))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsirprisingly we get basically the same results. Note additional parameter - `fan_out`.This parameter specified either to preserve the magnitude of variance of the weights either in the forward pass (`fan_in`) or in the backwards pass (`fan_out`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as discussed above, we can subtract 0.5 from our relu to get mean closer to zero\n",
    "def relu(x): return x.clamp_min(0) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple forward pass can be specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(x_train, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.6 ms ± 4.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, we will consider MSE loss function, although in our case it does not make any practical sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ): return (output.squeeze(-1)-targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.7334)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model(x_train)\n",
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we approach the backward pass and need to calculate the gradients of each pass. Let's start from MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    \"\"\"\n",
    "    we accumulate gradients during the backward pass\n",
    "    First, calculate the gradient of loss with respect to its input, which is the output of the previous layer\n",
    "    \"\"\"\n",
    "    inp.g = 2. * (inp.squeeze(-1) - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # gradient of relu with respect to its input layer\n",
    "    inp.g = (inp.float() > 0) * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul with respect to input\n",
    "    inp.g = out.g @ w.t()\n",
    "    #w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    w.g = inp.t() @ out.g\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w2 + b2\n",
    "    # not necessary to compute loss\n",
    "    loss = mse(out, targ)\n",
    "    \n",
    "    # backward pass:\n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our gradients\n",
    "w1g = w1.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "inp = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check our results against pytorch\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)\n",
    "xt2 = x_train.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pytorch calculates the backwards pass for us, we need only a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    l3 = l2 @ w22 + b22\n",
    "    return mse(l3, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have just checked that our gradients are correct, but the code itself is very clunky. Let's refactor it by using classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    # __call__ allows us to call Relu directly as a function\n",
    "    def __call__(self,inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.) - 0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): self.inp.g = (self.inp > 0.).float() * self.out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin():\n",
    "    def __init__(self, w, b): self.w, self.b = w, b\n",
    "    \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        #print(f\"out {self.out.g.shape}, w shape {self.w.shape}\")\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g =  self.inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "            \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 ms, sys: 83.6 ms, total: 230 ms\n",
      "Wall time: 31.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 305 ms, sys: 305 ms, total: 609 ms\n",
      "Wall time: 76.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(inp, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get rid of the unnecessary calls to `__call__` each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): raise Exception(\"not implemented\")\n",
    "        \n",
    "    def backward(self): self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
    "    \n",
    "    def bwd(self, out, inp): inp.g = (inp > 0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): self.w, self.b = w, b\n",
    "        \n",
    "    def forward(self, inp): return inp @ self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g =  inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Module):\n",
    "    def forward(self, inp, targ): return (inp.squeeze(-1)-targ).pow(2).mean()\n",
    "    \n",
    "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 82.6 ms, total: 258 ms\n",
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 298 ms, sys: 320 ms, total: 618 ms\n",
      "Wall time: 84.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(inp, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear and nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understanding of how this works, we can switch to pytorch modules - `nn.Linear` and `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "        self.loss = mse\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x.squeeze(), targ)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 150 ms, sys: 38.2 ms, total: 188 ms\n",
      "Wall time: 26.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 258 ms, sys: 39 ms, total: 297 ms\n",
      "Wall time: 37.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
